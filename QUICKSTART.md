# W4A16 Hopper Kernel - å¿«é€Ÿå¼€å§‹æŒ‡å—

## ç¼–è¯‘å®Œæˆ âœ“

W4A16 Hopper (SM90) kernel å·²ç»æˆåŠŸæå–å¹¶ç¼–è¯‘ï¼

## æ–‡ä»¶ä½ç½®

### åº“æ–‡ä»¶
```
/home/qianxu/trt_llm_w4a16_hopper/build/lib/libw4a16_sm90_kernel.so (2.7 MB)
```

### æµ‹è¯•ç¨‹åº
```
/home/qianxu/trt_llm_w4a16_hopper/build/bin/test_w4a16_sm90 (19 KB)
```

## å¿«é€Ÿæµ‹è¯•

```bash
cd /home/qianxu/trt_llm_w4a16_hopper/build
./bin/test_w4a16_sm90
```

## é‡æ–°ç¼–è¯‘

å¦‚æœéœ€è¦é‡æ–°ç¼–è¯‘ï¼š

```bash
cd /home/qianxu/trt_llm_w4a16_hopper/build
make clean
make -j4
```

æˆ–è€…å®Œå…¨é‡æ–°é…ç½®ï¼š

```bash
cd /home/qianxu/trt_llm_w4a16_hopper
rm -rf build
mkdir build
cd build
cmake ..
make -j4
```

## Kernel API

æä¾›äº†ä¸¤ä¸ªä¼˜åŒ–çš„ kernel å‡½æ•°ï¼š

### 1. w4a16_sm90_gemm_128 (å¤§çŸ©é˜µä¼˜åŒ–)

```cpp
extern "C" void w4a16_sm90_gemm_128(
    half const* A,                   // è¾“å…¥æ¿€æ´» [M, K]
    cutlass::uint4b_t const* B,     // INT4 æƒé‡ [N, K]
    half const* weight_scales,       // æƒé‡ç¼©æ”¾å› å­ [N, K/group_size]
    half const* weight_zero_points,  // é›¶ç‚¹ (å¯ä¸º nullptr)
    half const* biases,             // åç½® (å¯ä¸º nullptr)
    float const alpha,              // ç¼©æ”¾å› å­
    half* C,                        // è¾“å‡º [M, N]
    int m, int n, int k,            // çŸ©é˜µç»´åº¦
    int const group_size,           // é‡åŒ–åˆ†ç»„å¤§å° (é€šå¸¸ 128)
    CutlassGemmConfig gemm_config,  // GEMM é…ç½®
    char* workspace,                // å·¥ä½œç©ºé—´
    size_t workspace_bytes,         // å·¥ä½œç©ºé—´å¤§å°
    cudaStream_t stream,            // CUDA æµ
    int* occupancy                  // å ç”¨ç‡æŸ¥è¯¢ (å¯ä¸º nullptr)
);
```

### 2. w4a16_sm90_gemm_64 (å°çŸ©é˜µ/å†…å­˜ä¼˜åŒ–)

ç›¸åŒçš„å‡½æ•°ç­¾åï¼Œä½†ä½¿ç”¨ä¸åŒçš„ CTA é…ç½®ã€‚

## åœ¨ä½ çš„é¡¹ç›®ä¸­ä½¿ç”¨

### æ–¹æ³• 1: é“¾æ¥å…±äº«åº“

```bash
g++ -o my_app my_app.cpp \
    -L/home/qianxu/trt_llm_w4a16_hopper/build/lib \
    -lw4a16_sm90_kernel \
    -lcudart \
    -I/home/qianxu/trt_llm_w4a16_hopper/include \
    -I/home/qianxu/TensorRT-LLM/3rdparty/cutlass/include
```

### æ–¹æ³• 2: è¿è¡Œæ—¶åŠ è½½

```cpp
#include <dlfcn.h>

void* handle = dlopen("libw4a16_sm90_kernel.so", RTLD_LAZY);
auto kernel = (decltype(&w4a16_sm90_gemm_128))dlsym(handle, "w4a16_sm90_gemm_128");
// ä½¿ç”¨ kernel...
dlclose(handle);
```

## ç®€å•ç¤ºä¾‹

```cpp
#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <iostream>

extern "C" void w4a16_sm90_gemm_128(
    half const* A, void const* B,
    half const* scales, half const* zeros,
    half const* bias, float alpha, half* C,
    int m, int n, int k, int group_size,
    void* config, char* workspace, size_t ws_bytes,
    cudaStream_t stream, int* occ
);

int main() {
    // çŸ©é˜µç»´åº¦
    int M = 1024, N = 4096, K = 4096;
    int group_size = 128;

    // åˆ†é…è®¾å¤‡å†…å­˜
    half *d_A, *d_C, *d_scales;
    void *d_B;
    char *d_workspace;

    cudaMalloc(&d_A, M * K * sizeof(half));
    cudaMalloc(&d_B, N * K / 2);  // INT4 æ¯ä¸ªå…ƒç´  0.5 å­—èŠ‚
    cudaMalloc(&d_scales, N * (K/group_size) * sizeof(half));
    cudaMalloc(&d_C, M * N * sizeof(half));
    cudaMalloc(&d_workspace, 4*1024*1024);  // 4MB å·¥ä½œç©ºé—´

    // åˆå§‹åŒ–æ•°æ®...
    // (ä½ çš„æ•°æ®åŠ è½½ä»£ç )

    // è°ƒç”¨ kernel
    w4a16_sm90_gemm_128(
        d_A, d_B, d_scales,
        nullptr,  // æ— é›¶ç‚¹
        nullptr,  // æ— åç½®
        1.0f,     // alpha
        d_C,
        M, N, K,
        group_size,
        nullptr,  // é»˜è®¤é…ç½®
        d_workspace,
        4*1024*1024,
        0,        // é»˜è®¤æµ
        nullptr   // ä¸æŸ¥è¯¢å ç”¨ç‡
    );

    cudaDeviceSynchronize();

    // é‡Šæ”¾å†…å­˜
    cudaFree(d_A);
    cudaFree(d_B);
    cudaFree(d_scales);
    cudaFree(d_C);
    cudaFree(d_workspace);

    return 0;
}
```

ç¼–è¯‘ç¤ºä¾‹ï¼š
```bash
nvcc example.cpp -o example \
    -L/home/qianxu/trt_llm_w4a16_hopper/build/lib \
    -lw4a16_sm90_kernel \
    -I/home/qianxu/trt_llm_w4a16_hopper/include
```

## å…¼å®¹æ€§

- **ç›®æ ‡æ¶æ„**: SM90 (Hopper)
- **æµ‹è¯•æ¶æ„**: SM120 (RTX 5070) - å‘åå…¼å®¹ âœ“
- **CUDA ç‰ˆæœ¬**: 12.8+ æ¨è
- **é‡åŒ–æ ¼å¼**: W4A16 (4-bit weights, 16-bit activations)

## æ€§èƒ½æç¤º

1. **é€‰æ‹©æ­£ç¡®çš„ kernel**:
   - å¤§çŸ©é˜µ (MÃ—NÃ—K > 1M): ä½¿ç”¨ `w4a16_sm90_gemm_128`
   - å°çŸ©é˜µæˆ–å†…å­˜å—é™: ä½¿ç”¨ `w4a16_sm90_gemm_64`

2. **Group Size**:
   - æ¨èå€¼: 128 æˆ– 64
   - å¿…é¡»æ˜¯ 128 çš„å€æ•°ï¼ˆå¯¹äº 128x128x128 CTAï¼‰

3. **å·¥ä½œç©ºé—´**:
   - åˆ†é…è¶³å¤Ÿçš„å·¥ä½œç©ºé—´ï¼ˆå»ºè®® 4-8 MBï¼‰
   - å¯ä»¥å¤ç”¨å·¥ä½œç©ºé—´ä»¥èŠ‚çœå†…å­˜

4. **CUDA æµ**:
   - ä½¿ç”¨ä¸åŒçš„æµæ¥å¹¶è¡Œæ‰§è¡Œå¤šä¸ª kernel

## æ•…éšœæ’é™¤

### ç¼–è¯‘é”™è¯¯

å¦‚æœé‡åˆ°ç¼–è¯‘é”™è¯¯ï¼š
```bash
cd /home/qianxu/trt_llm_w4a16_hopper/build
make clean
cmake .. -DCUTLASS_DIR=/home/qianxu/TensorRT-LLM/3rdparty/cutlass
make -j4
```

### è¿è¡Œæ—¶é”™è¯¯

- æ£€æŸ¥ GPU æ¶æ„æ˜¯å¦å…¼å®¹ï¼ˆéœ€è¦ SM90+ï¼‰
- ç¡®ä¿åˆ†é…äº†è¶³å¤Ÿçš„å·¥ä½œç©ºé—´
- éªŒè¯ group_size æ˜¯å¦æ­£ç¡®ï¼ˆå¿…é¡»æ•´é™¤ Kï¼‰

### é“¾æ¥é”™è¯¯

ç¡®ä¿åº“è·¯å¾„æ­£ç¡®ï¼š
```bash
export LD_LIBRARY_PATH=/home/qianxu/trt_llm_w4a16_hopper/build/lib:$LD_LIBRARY_PATH
```

## æ›´å¤šä¿¡æ¯

- è¯¦ç»†æ–‡æ¡£: [BUILD_SUCCESS.md](BUILD_SUCCESS.md)
- æå–æ‘˜è¦: [EXTRACTION_SUMMARY.md](EXTRACTION_SUMMARY.md)
- å®Œæ•´è¯´æ˜: [README.md](README.md)

## Git å†å²

æŸ¥çœ‹æå–å’Œæ„å»ºå†å²ï¼š
```bash
git log --oneline
```

æ¯ä¸ª commit éƒ½å¯¹åº”æå–è¿‡ç¨‹çš„ä¸€ä¸ªæ­¥éª¤ã€‚

---

ğŸ‰ æ­å–œï¼ä½ å·²ç»æˆåŠŸæå–å¹¶ç¼–è¯‘äº† W4A16 Hopper kernelï¼
