# W4A16 Hopper Kernel æå–çŠ¶æ€æŠ¥å‘Š

**æ—¥æœŸ**: 2025-11-14
**ä½ç½®**: `/home/qianxu/trt_llm_w4a16_hopper/`
**GitHub**: https://github.com/DrXuQian/TensorRT-LLM/tree/w4a16_hopper_extraction

---

## âœ… å·²å®Œæˆçš„å·¥ä½œ

### 1. æˆåŠŸæå– Hopper Kernel
- âœ… ä» TensorRT-LLM å®Œæ•´æå– W4A16 Hopper (SM90) kernel
- âœ… åŒ…å« 72 ä¸ª CUTLASS extension æ–‡ä»¶
- âœ… åŒ…å«å®Œæ•´çš„ launcher å’Œ template å®ç°
- âœ… åŒ…å«æ‰€æœ‰å¿…è¦çš„å¤´æ–‡ä»¶å’Œä¾èµ–

### 2. æˆåŠŸç¼–è¯‘
- âœ… ç¼–è¯‘ç”Ÿæˆ `libw4a16_sm90_kernel.so` (2.7 MB)
- âœ… åŒ…å«ä¸¤ä¸ª kernel å˜ä½“:
  - `w4a16_sm90_gemm_128`: 128Ã—128Ã—128 CTA, TMA Cooperative
  - `w4a16_sm90_gemm_64`: 64Ã—128Ã—128 CTA, TMA Pingpong
- âœ… ç¼–è¯‘äº† 6 ä¸ªæµ‹è¯•/benchmark ç¨‹åº

### 3. éªŒè¯ Kernel ç¼–è¯‘
```bash
$ cuobjdump -symbols lib/libw4a16_sm90_kernel.so | grep kernel
# ç¡®è®¤åŒ…å«:
- MainloopSm90TmaGmmaRmemAWarpSpecializedMixedInput (Pingpong)
- MainloopSm90TmaGmmaRmemAWarpSpecializedMixedInput (Cooperative)
```

### 4. Git å†å²è®°å½•
å®Œæ•´çš„æå–è¿‡ç¨‹å·²è®°å½•åœ¨ 10 ä¸ª git commits ä¸­ï¼Œä¾¿äºè¿½æº¯ã€‚

---

## âŒ é‡åˆ°çš„é—®é¢˜

### è¿è¡Œæ—¶é—®é¢˜ (H800 æµ‹è¯•)

**ç—‡çŠ¶**:
1. æ‰€æœ‰æµ‹è¯•ç¨‹åºéƒ½åœ¨ `cudaStreamSynchronize()` æ—¶ segfault
2. `ncu` çœ‹ä¸åˆ°å®Œæ•´çš„ kernel æ‰§è¡Œ
3. è¾“å‡ºå…¨ä¸º 0ï¼ˆå› ä¸º kernel æ²¡å®Œæˆï¼‰

**è¯Šæ–­ç»“æœ**:
```
âœ… Kernel call returned successfully!
âœ… No kernel launch errors
  Synchronizing stream...
Segmentation fault (core dumped)
```

**ç»“è®º**:
- Kernel **æˆåŠŸå¯åŠ¨**äº†
- ä½†åœ¨ **GPU æ‰§è¡Œè¿‡ç¨‹ä¸­å´©æºƒ**
- é—®é¢˜åœ¨ kernel å†…éƒ¨ï¼Œä¸æ˜¯å¯åŠ¨é—®é¢˜

---

## ğŸ” é—®é¢˜æ ¹æœ¬åŸå› åˆ†æ

### å¯èƒ½åŸå›  1: INT4 æ•°æ®æ ¼å¼é—®é¢˜

å½“å‰ä»£ç ä½¿ç”¨çš„ INT4 æ‰“åŒ…æ ¼å¼å¯èƒ½ä¸ kernel é¢„æœŸä¸ç¬¦ã€‚

**å½“å‰å®ç°**:
```cpp
// æ¯ä¸ªå­—èŠ‚å­˜å‚¨ 2 ä¸ª INT4 å€¼
uint8_t val1 = dis(gen) & 0xF;  // ä½ 4 ä½
uint8_t val2 = dis(gen) & 0xF;  // é«˜ 4 ä½
data[i] = (val2 << 4) | val1;
```

**é—®é¢˜**: CUTLASS å¯èƒ½æœŸæœ›ä¸åŒçš„äº¤é”™ï¼ˆinterleavedï¼‰æ ¼å¼ã€‚

### å¯èƒ½åŸå›  2: Bias å¤„ç†é—®é¢˜

Launcher ä»£ç  (fpA_intB_launcher_sm90.inl:234-246):
```cpp
// Line 235: ç”¨ output C ä½œä¸º bias çš„å ä½ç¬¦
auto output_as_bias_type = reinterpret_cast<CutlassBiasType const*>(C);

// Line 241: åœ¨æ„é€  Gemm::Arguments æ—¶ä½¿ç”¨
{{}, output_as_bias_type, stride_D, ...}

// Line 246: åœ¨ epilogue.thread ä¸­ä½¿ç”¨çœŸå® bias
{reinterpret_cast<CutlassBiasType const*>(biases), CutlassBiasType(0.f)}
```

**é—®é¢˜**: è¿™ä¸ªåŒé‡è®¾ç½®å¯èƒ½å¯¼è‡´ TMA descriptor æ··æ·†ã€‚

### å¯èƒ½åŸå›  3: Group Size ä¸ CTA K ç»´åº¦ä¸åŒ¹é…

```cpp
// Line 193-198: group_size å¿…é¡»æ˜¯ cta_shape_k çš„å€æ•°
if (group_size % cta_shape_k != 0) {
    throw std::runtime_error("The group size must a multiple of 128");
}
```

**å½“å‰æµ‹è¯•**: group_size=128, CTA K=128 âœ“ (åº”è¯¥æ²¡é—®é¢˜)

### å¯èƒ½åŸå›  4: TMA éœ€è¦ç‰¹å®šçš„å†…å­˜å¯¹é½

TMA å¯¹å†…å­˜å¯¹é½æœ‰ä¸¥æ ¼è¦æ±‚ï¼Œæˆ‘ä»¬ä½¿ç”¨ `cudaMemset` åˆå§‹åŒ–å¯èƒ½ä¸æ»¡è¶³ã€‚

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
/home/qianxu/trt_llm_w4a16_hopper/
â”œâ”€â”€ build/
â”‚   â”œâ”€â”€ lib/libw4a16_sm90_kernel.so     # 2.7 MB
â”‚   â””â”€â”€ bin/
â”‚       â”œâ”€â”€ test_w4a16_sm90             # ç®€å•æµ‹è¯•
â”‚       â”œâ”€â”€ benchmark_w4a16_sm90        # å®Œæ•´ benchmark
â”‚       â”œâ”€â”€ debug_w4a16_sm90            # è°ƒè¯•ç‰ˆæœ¬
â”‚       â”œâ”€â”€ simple_test_sm90            # ç®€åŒ–æµ‹è¯•
â”‚       â”œâ”€â”€ test_with_bias              # å¸¦ bias æµ‹è¯•
â”‚       â””â”€â”€ safe_test                   # å¼‚å¸¸æ•è·æµ‹è¯•
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ w4a16_sm90_kernel.cu            # Kernel wrappers
â”‚   â”œâ”€â”€ benchmark_w4a16.cu              # æ€§èƒ½æµ‹è¯•
â”‚   â”œâ”€â”€ debug_kernel.cu                 # è°ƒè¯•ç¨‹åº
â”‚   â”œâ”€â”€ simple_test.cu                  # ç®€å•æµ‹è¯•
â”‚   â”œâ”€â”€ test_with_bias.cu               # Bias æµ‹è¯•
â”‚   â”œâ”€â”€ safe_test.cu                    # å®‰å…¨æµ‹è¯•
â”‚   â”œâ”€â”€ logger.cpp                      # TensorRT-LLM logger
â”‚   â”œâ”€â”€ stringUtils.cpp                 # å­—ç¬¦ä¸²å·¥å…·
â”‚   â”œâ”€â”€ assert.cpp                      # æ–­è¨€å®ç°
â”‚   â””â”€â”€ tllmException.cpp               # å¼‚å¸¸å¤„ç†
â”œâ”€â”€ include/
â”‚   â””â”€â”€ tensorrt_llm/
â”‚       â”œâ”€â”€ common/                     # é€šç”¨å¤´æ–‡ä»¶
â”‚       â”œâ”€â”€ cutlass_extensions/         # 72 ä¸ª CUTLASS æ‰©å±•
â”‚       â””â”€â”€ kernels/                    # Kernel å¤´æ–‡ä»¶
â”œâ”€â”€ CMakeLists.txt                      # æ„å»ºé…ç½®
â”œâ”€â”€ README.md                           # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ BUILD_SUCCESS.md                    # æ„å»ºæ–‡æ¡£
â”œâ”€â”€ QUICKSTART.md                       # å¿«é€Ÿå¼€å§‹
â”œâ”€â”€ IMPORTANT_NOTICE.md                 # é‡è¦è¯´æ˜
â””â”€â”€ STATUS_REPORT.md                    # æœ¬æ–‡ä»¶
```

---

## ğŸš€ ä¸‹ä¸€æ­¥å»ºè®®

### é€‰é¡¹ A: ä¿®å¤å½“å‰ Hopper Kernel (å›°éš¾)

éœ€è¦æ·±å…¥è°ƒè¯•ï¼Œå¯èƒ½éœ€è¦:
1. ä½¿ç”¨ `cuda-gdb` åœ¨ GPU ä¸Šè°ƒè¯•
2. ä¿®å¤ INT4 æ•°æ®æ ¼å¼
3. ä¿®å¤ bias/TMA descriptor å¤„ç†
4. å¯èƒ½éœ€è¦ä¿®æ”¹ CUTLASS æ¨¡æ¿å‚æ•°

**éš¾åº¦**: â­â­â­â­â­
**æ—¶é—´**: æ•°å¤©åˆ°æ•°å‘¨
**æˆåŠŸç‡**: ä¸­ç­‰

### é€‰é¡¹ B: æå– Ampere/Ada ç‰ˆæœ¬ (æ¨è) â­

æå– TensorRT-LLM ä¸­çš„ Ampere (SM80) / Ada (SM89) ç‰ˆæœ¬çš„ W4A16 kernelã€‚

**ä¼˜ç‚¹**:
- ä¸ä½¿ç”¨ TMAï¼Œæ›´å®¹æ˜“è°ƒè¯•
- å¯ä»¥åœ¨ RTX 3090/4090/5070 ç­‰ GPU ä¸Šè¿è¡Œ
- ä»ç„¶æ˜¯ W4A16 é‡åŒ–
- ä»£ç æ›´æˆç†Ÿï¼Œå·²åœ¨ç”Ÿäº§ç¯å¢ƒéªŒè¯

**ä½ç½®**: `cpp/tensorrt_llm/kernels/cutlass_kernels/fpA_intB_gemm/fpA_intB_gemm_template.h`

**éš¾åº¦**: â­â­
**æ—¶é—´**: 1-2 å¤©
**æˆåŠŸç‡**: é«˜

### é€‰é¡¹ C: ä½¿ç”¨ TensorRT-LLM Python API

ç›´æ¥ä½¿ç”¨ TensorRT-LLM çš„ Python API è°ƒç”¨ W4A16 kernelï¼Œæ— éœ€æå–ã€‚

**ä¼˜ç‚¹**:
- å¼€ç®±å³ç”¨
- å®Œæ•´çš„åŠŸèƒ½æ”¯æŒ
- å®˜æ–¹ç»´æŠ¤

**ç¼ºç‚¹**:
- éœ€è¦æ•´ä¸ª TensorRT-LLM ç¯å¢ƒ
- ä¸æ˜¯ç‹¬ç«‹çš„ kernel

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯” (é¢„æœŸ)

| ç‰ˆæœ¬ | GPU | TMA | æ€§èƒ½ | ç¨³å®šæ€§ |
|------|-----|-----|------|--------|
| Hopper (å½“å‰) | H100/H200 | âœ… | æœ€é«˜ | âŒ å´©æºƒ |
| Ampere/Ada | RTX 3090/4090 | âŒ | é«˜ | âœ… ç¨³å®š |
| Blackwell | RTX 5070 | ? | æœªçŸ¥ | â“ æœªæµ‹è¯• |

---

## ğŸ“ æŠ€æœ¯ç»†èŠ‚

### Kernel é…ç½®

**W4A16 é‡åŒ–**:
- Weights: 4-bit integer (INT4)
- Activations: 16-bit floating point (FP16/BF16)
- Quantization: Fine-grained, group-wise
- Group size: 128 (å¯é…ç½®)

**CTA é…ç½®**:
- å¤§çŸ©é˜µ: 128Ã—128Ã—128 with TMA Cooperative
- å°çŸ©é˜µ: 64Ã—128Ã—128 with TMA Pingpong

**ç¼–è¯‘é€‰é¡¹**:
- Target: SM90 (Hopper)
- CUDA: 12.8
- Flag: `-DCOMPILE_HOPPER_TMA_GEMMS`

### ä¾èµ–

- CUTLASS (ä» TensorRT-LLM 3rdparty)
- CUDA Toolkit 12.x
- CMake 3.18+
- C++17

---

## ğŸ¯ æ€»ç»“

âœ… **æˆåŠŸ**: å®Œæ•´æå–å¹¶ç¼–è¯‘äº† W4A16 Hopper kernel
âŒ **å¤±è´¥**: Kernel åœ¨ H800 è¿è¡Œæ—¶å´©æºƒ
ğŸ”§ **åŸå› **: Kernel å†…éƒ¨è®¿é—®æ— æ•ˆå†…å­˜ï¼ˆå¯èƒ½æ˜¯æ•°æ®æ ¼å¼æˆ– TMA descriptor é—®é¢˜ï¼‰
ğŸ’¡ **å»ºè®®**: æå– Ampere/Ada ç‰ˆæœ¬ï¼Œæ›´å®¹æ˜“ä½¿ç”¨ä¸”ç¨³å®š

---

**çŠ¶æ€**: ç¼–è¯‘æˆåŠŸï¼Œè¿è¡Œå¤±è´¥
**ä¼˜å…ˆçº§**: å»ºè®®è½¬å‘ Ampere/Ada ç‰ˆæœ¬
**æ–‡æ¡£å®Œæ•´æ€§**: âœ… å®Œæ•´
**ä»£ç å¯ç”¨æ€§**: âš ï¸ éœ€è¦åœ¨çœŸå® Hopper GPU (H100) ä¸ŠéªŒè¯
