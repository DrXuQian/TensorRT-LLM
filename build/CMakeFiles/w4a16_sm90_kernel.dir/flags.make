# CMAKE generated file: DO NOT EDIT!
# Generated by "Unix Makefiles" Generator, CMake Version 3.22

# compile CUDA with /usr/local/cuda-12.8/bin/nvcc
# compile CXX with /usr/bin/c++
CUDA_DEFINES = -DCOMPILE_HOPPER_TMA_GEMMS -Dw4a16_sm90_kernel_EXPORTS

CUDA_INCLUDES = -I/home/qianxu/trt_llm_w4a16_hopper/include -I/home/qianxu/trt_llm_w4a16_hopper/include/tensorrt_llm/cutlass_extensions/include -I/home/qianxu/TensorRT-LLM/3rdparty/cutlass/include -I/home/qianxu/TensorRT-LLM/3rdparty/cutlass/tools/util/include -isystem=/usr/local/cuda-12.8/include

CUDA_FLAGS =  -Xcompiler=-fPIC -Xcompiler=-Wall --expt-relaxed-constexpr --expt-extended-lambda -Xcudafe --diag_suppress=186 --generate-code=arch=compute_90,code=[compute_90,sm_90] -Xcompiler=-fPIC -std=c++17

CXX_DEFINES = -DCOMPILE_HOPPER_TMA_GEMMS -Dw4a16_sm90_kernel_EXPORTS

CXX_INCLUDES = -I/home/qianxu/trt_llm_w4a16_hopper/include -I/home/qianxu/trt_llm_w4a16_hopper/include/tensorrt_llm/cutlass_extensions/include -I/home/qianxu/TensorRT-LLM/3rdparty/cutlass/include -I/home/qianxu/TensorRT-LLM/3rdparty/cutlass/tools/util/include -isystem /usr/local/cuda-12.8/include

CXX_FLAGS = -fPIC -std=gnu++17

